# Spark 3.5 LTS Default Configuration
# This file should be placed in $SPARK_HOME/conf/

# Spark Application Properties
spark.app.name                    PySpark-Streaming-App
spark.master                      spark://localhost:7077

# Spark Driver Configuration
spark.driver.memory               1g
spark.driver.maxResultSize        512m
spark.driver.cores                1

# Spark Executor Configuration
spark.executor.memory             1g
spark.executor.cores              2
spark.executor.instances          2

# Spark SQL Configuration
spark.sql.adaptive.enabled                    true
spark.sql.adaptive.coalescePartitions.enabled true
spark.sql.adaptive.skewJoin.enabled           true
spark.sql.adaptive.localShuffleReader.enabled true

# Spark Streaming Configuration
spark.streaming.receiver.maxRate              1000
spark.streaming.kafka.maxRatePerPartition     1000
spark.streaming.backpressure.enabled          true
spark.streaming.dynamicAllocation.enabled     false

# Spark Serialization
spark.serializer                   org.apache.spark.serializer.KryoSerializer
spark.kryo.registrationRequired    false

# Spark Shuffle Configuration
spark.shuffle.compress             true
spark.shuffle.spill.compress       true
spark.shuffle.service.enabled      true

# Spark History Server
spark.eventLog.enabled             true
spark.eventLog.dir                 /app/logs/spark-events
spark.history.fs.logDirectory      /app/logs/spark-events

# Spark UI Configuration
spark.ui.enabled                   true
spark.ui.port                      4040
spark.ui.retainedJobs             100
spark.ui.retainedStages           100

# Kafka Integration
spark.jars.packages               org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1

# Network Configuration
spark.network.timeout             120s
spark.rpc.askTimeout              120s
spark.rpc.lookupTimeout           120s

# Dynamic Allocation (disabled for streaming)
spark.dynamicAllocation.enabled                false
spark.dynamicAllocation.minExecutors           1
spark.dynamicAllocation.maxExecutors           4
spark.dynamicAllocation.initialExecutors       2

# Checkpoint Configuration
spark.sql.streaming.checkpointLocation         /app/checkpoints

# Python Configuration
spark.pyspark.python              python3
spark.pyspark.driver.python       python3

# Logging Level
spark.sql.execution.arrow.pyspark.enabled      true